{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF85VWAq0/dFsme4qIKzYp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22vb/PRODIGY_DS-03/blob/main/PRODIGY_DS_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O4XnEAaO2VX",
        "outputId": "ea5576eb-7a0f-4d6b-cb15-51dbba6aef64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "   PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
            "% of women who survived: 0.7420382165605095\n",
            "% of men who survived: 0.18890814558058924\n",
            "Your submission was successfully saved!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Set the path to the dataset\n",
        "data_path = '/kaggle/input'\n",
        "\n",
        "# Print the files in the dataset directory\n",
        "for dirname, _, filenames in os.walk(data_path):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Load the training and test data\n",
        "train_file_path = os.path.join(data_path, '/content/TRAINING.csv')\n",
        "test_file_path = os.path.join(data_path, '/content/TESTING.csv')\n",
        "\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# Display the first few rows of the datasets\n",
        "print(train_data.head())\n",
        "print(test_data.head())\n",
        "\n",
        "# Calculate the survival rates for women and men\n",
        "women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n",
        "rate_women = sum(women) / len(women)\n",
        "print(\"% of women who survived:\", rate_women)\n",
        "\n",
        "men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\n",
        "rate_men = sum(men) / len(men)\n",
        "print(\"% of men who survived:\", rate_men)\n",
        "\n",
        "# Prepare the data for the model\n",
        "y = train_data[\"Survived\"]\n",
        "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
        "X = pd.get_dummies(train_data[features])\n",
        "X_test = pd.get_dummies(test_data[features])\n",
        "\n",
        "# Ensure the feature columns are the same in both train and test data\n",
        "X, X_test = X.align(X_test, join='left', axis=1)\n",
        "\n",
        "# Train the Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
        "model.fit(X, y)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Create the submission file\n",
        "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
        "output.to_csv('submission.csv', index=False)\n",
        "print(\"Your submission was successfully saved!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import zipfile\n",
        "import io # Import the io module to work with in-memory file-like objects\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip'\n",
        "# Fetch the zip file\n",
        "import requests\n",
        "response = requests.get(url)\n",
        "\n",
        "# Extract the zip file in memory\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    # Assuming 'bank-additional/bank-additional-full.csv' is the file you need\n",
        "    with z.open('bank-additional/bank-additional-full.csv') as f:\n",
        "        bank_df = pd.read_csv(f, sep=';')\n",
        "\n",
        "# Display the first few rows\n",
        "print(bank_df.head())\n",
        "\n",
        "\n",
        "# Check for missing values\n",
        "print(bank_df.isnull().sum())\n",
        "\n",
        "# Define features and target variable\n",
        "X = bank_df.drop('y', axis=1)\n",
        "y = bank_df['y']\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Define preprocessing for numerical columns (scale them)\n",
        "numeric_transformer = StandardScaler()\n",
        "\n",
        "# Define preprocessing for categorical columns (encode them)\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Create preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the decision tree classifier\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', DecisionTreeClassifier(random_state=42))])\n",
        "\n",
        "# Fit the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHpm1F1qWyp4",
        "outputId": "8a84b1da-4ac5-46c0-c18e-6ae6990614ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age        job  marital    education  default housing loan    contact  \\\n",
            "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
            "1   57   services  married  high.school  unknown      no   no  telephone   \n",
            "2   37   services  married  high.school       no     yes   no  telephone   \n",
            "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
            "4   56   services  married  high.school       no      no  yes  telephone   \n",
            "\n",
            "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
            "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "\n",
            "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
            "0          93.994          -36.4      4.857       5191.0  no  \n",
            "1          93.994          -36.4      4.857       5191.0  no  \n",
            "2          93.994          -36.4      4.857       5191.0  no  \n",
            "3          93.994          -36.4      4.857       5191.0  no  \n",
            "4          93.994          -36.4      4.857       5191.0  no  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "age               0\n",
            "job               0\n",
            "marital           0\n",
            "education         0\n",
            "default           0\n",
            "housing           0\n",
            "loan              0\n",
            "contact           0\n",
            "month             0\n",
            "day_of_week       0\n",
            "duration          0\n",
            "campaign          0\n",
            "pdays             0\n",
            "previous          0\n",
            "poutcome          0\n",
            "emp.var.rate      0\n",
            "cons.price.idx    0\n",
            "cons.conf.idx     0\n",
            "euribor3m         0\n",
            "nr.employed       0\n",
            "y                 0\n",
            "dtype: int64\n",
            "[[6810  493]\n",
            " [ 440  495]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.94      0.93      0.94      7303\n",
            "         yes       0.50      0.53      0.51       935\n",
            "\n",
            "    accuracy                           0.89      8238\n",
            "   macro avg       0.72      0.73      0.73      8238\n",
            "weighted avg       0.89      0.89      0.89      8238\n",
            "\n"
          ]
        }
      ]
    }
  ]
}